---
layout: post
title: "[Generative-model] DDPM"
description: >
  DDPM 논문 요약
category: seminar
tags: generative-model
author: jh_yun
comments: true
---

# Denoising Diffusion Probabilistic Models

- Jonathan Ho et al., Denoising Diffusion Probabilistic Models, NeurIPS, 2020

# Goal

- [J. Sohl-Dickstein et al., Deep Unsupervised Learning using Nonequilibrium Thermodynamics, ICML 2015]에서 제안한 Diffuision model을 더욱 발전시키고자 Denoising 네트워크를 학습시킴으로써 좋은 성능의 이미지 생성모델을 제안함

# Motivation

- GAN, Autoregressive model, Flow, VAE 등 다양한 생성모델들이 많은 성공을 이룸
- Diffusion model이 High quality 샘플을 생성한다는 사실이 입증된 바 없음

# Contribution

- Diffusion model의 High quality 샘플을 생성할 수 있는 능력을 증명함
- 특정한 Parameterization을 통해서, Denoising score matching과 유사한 형태의 Objective를 갖는다는 것과 Langevin dynamics와 유사한 Sampling 형태를 갖는다는 것을 보임

---

# Diffusion 모델이란?

![https://private-user-images.githubusercontent.com/144989499/288603528-6513e341-850a-4a6a-9eec-f364647d832e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNTI4LTY1MTNlMzQxLTg1MGEtNGE2YS05ZWVjLWYzNjQ2NDdkODMyZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kZDJmZjU4OTNiMDkzMDRiOTExMzg2OWYxOGVmY2FkZDlhNTMzOWNlNWQ2NDM4YWRhOTM0NWJlYmMwNGQzNGVkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ECgJf2DSLth3jlegaFtf1H7Lwivj7cfOZ5bVeJsiY34](https://private-user-images.githubusercontent.com/144989499/288603528-6513e341-850a-4a6a-9eec-f364647d832e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNTI4LTY1MTNlMzQxLTg1MGEtNGE2YS05ZWVjLWYzNjQ2NDdkODMyZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kZDJmZjU4OTNiMDkzMDRiOTExMzg2OWYxOGVmY2FkZDlhNTMzOWNlNWQ2NDM4YWRhOTM0NWJlYmMwNGQzNGVkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ECgJf2DSLth3jlegaFtf1H7Lwivj7cfOZ5bVeJsiY34)

디퓨전 모델은 크게 2가지 Process로 구성이 되어있습니다. 

- **Forward process**는 원본 데이터 $x_0$에 노이즈를 조금씩 더해서 가우시안 노이즈인 $x_T$ 를 만드는 과정입니다. Diffusion process라고도 불리며, 총 $T$번의 과정을 통해서 깨끗한 이미지를 알아볼 수 없게 망가뜨리는 과정으로 이해하셔도 됩니다.
- **Reverse process**는 포워드 과정의 역과정으로, 가우시안 노이즈 $x_T$에서 노이즈를 조금씩 빼면서 원본 데이터 $x_0$를 만드는 과정입니다. Denoising process라고도 불리며, 실제로 생성모델이 데이터(이미지)를 생성하는 과정을 뜻합니다.

본 논문에서는 원본 데이터 $x_0$에서 시작해 조금씩 노이즈를 더해주는 Forward process를 마르코프 체인을 통해 정의하였습니다.

- **마르코프 체인**이란? 쉽게 말해서 현재 시점($t$)의 상태는 오직 이전 시점($t-1$)의 상태에 의존한다는 것입니다. 수식으로 표현하면 아래와 같습니다.
    
    $$
    q(x_t | x_0, x_1,x_2,...,x_{t-1}) = q(x_t | x_{t-1})
    $$
    
    마르코프 체인이라는 용어가 낯설다고 해서 어려워하지 않으셔도 됩니다. 오히려 임의의 $k$번째 상태의 이미지 $x_k$를 구하고 싶을 때, 초기 이미지인 $x_0,x_1,x_2,...$ 들을 고려하지 않고 $x_{k-1}$만 알면 구할 수 있는 것입니다.
    

![https://private-user-images.githubusercontent.com/144989499/288603570-8d12c7fb-9757-4974-b69e-80ca4ae6ec7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNTcwLThkMTJjN2ZiLTk3NTctNDk3NC1iNjllLTgwY2E0YWU2ZWM3Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yMjJmYWI4NWE2NjQxMzY2NDRkZWU1ZTBiYWM3NGU4MmQ5MDZhODQ2YWU2ZTAzNzM1MTg0MjQzNjg5ZTM0OWE4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.Uq4snpFTkFlbmbBeSMwJmdNOj0r1QnNwlRQQDHT8rBg](https://private-user-images.githubusercontent.com/144989499/288603570-8d12c7fb-9757-4974-b69e-80ca4ae6ec7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNTcwLThkMTJjN2ZiLTk3NTctNDk3NC1iNjllLTgwY2E0YWU2ZWM3Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yMjJmYWI4NWE2NjQxMzY2NDRkZWU1ZTBiYWM3NGU4MmQ5MDZhODQ2YWU2ZTAzNzM1MTg0MjQzNjg5ZTM0OWE4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.Uq4snpFTkFlbmbBeSMwJmdNOj0r1QnNwlRQQDHT8rBg)

위 사진에서도 나와있지만, 하나 알고계셔야할 점은 노이즈를 더해주는 **Forward process**는 학습을 통해서 얻어지는 것이 아니라, 마르코프 체인 혹은 쉽게 말해서 **수학에 의해 이미 결정되어 있습니다**. 다른 형태의 Latent variable model들을 생각해보면, 원본 데이터 $x_0$를 Latent variable로 만드는 과정도 네트워크가 학습을 통해 배우게 되지만, 디퓨전 모델은 Latent variable을 만드는 과정이 이미 Fix 되어있습니다. 

즉, **네트워크가 학습할 내용은 오직 Reverse process에 담겨있습니다.** 네트워크는 무엇을 학습하게 될까요? 네트워크는 어떠한 노이즈가 낀 데이터가 인풋으로 들어왔을 때, **노이즈를 얼마만큼 제거할 것인지를 학습**하게 됩니다. 자세한 이야기는 밑에서 다루도록 하겠습니다.

## Forward process

![https://private-user-images.githubusercontent.com/144989499/288603593-95ba2d0f-31f6-4950-bb54-9cc171a2eaba.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNTkzLTk1YmEyZDBmLTMxZjYtNDk1MC1iYjU0LTljYzE3MWEyZWFiYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wNDNiODQzMzI3NjMxODY0ZDYzZjg1ZGJkYjcxMGI2MGI3NzY1YmFhNjQwZWFmOTRiYWE1NmRiZmU5OTIyZTJiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.tJdhYacPIM23Na8UO3rdkwaT07Kryb1XgL612QxOm7k](https://private-user-images.githubusercontent.com/144989499/288603593-95ba2d0f-31f6-4950-bb54-9cc171a2eaba.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNTkzLTk1YmEyZDBmLTMxZjYtNDk1MC1iYjU0LTljYzE3MWEyZWFiYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wNDNiODQzMzI3NjMxODY0ZDYzZjg1ZGJkYjcxMGI2MGI3NzY1YmFhNjQwZWFmOTRiYWE1NmRiZmU5OTIyZTJiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.tJdhYacPIM23Na8UO3rdkwaT07Kryb1XgL612QxOm7k)

앞서 말씀드렸듯이 데이터를 더럽히는 Forward process는 이미 어떻게 노이즈를 더해줄지 결정되어있습니다. 즉, Posterior 분포는 마르코프 체인에 의해 고정되어 있습니다. 수식으로 표현하면 아래와 같습니다.

$$
* \ q(x_{1:T} | x_0):= \Pi^T_{t=1}q(x_{t} | x_{t-1})
$$

$$
* \ q(x_t | x_{t-1}):=N(x_{t} ; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)
$$

(앞에 $*$가 붙은 수식은 매우 중요하다는 것을 의미합니다)

더욱 직관적으로 이해해보자면, Forward process는 $x_{t-1}$ 상태에서 $x_t$로 넘어가는 과정에서 노이즈를 조금씩 더해주고 있습니다. 

$$
x_t=x_{t-1} +noise
$$

근데 노이즈를 얼마나 줄지에 대한 노이즈 스케일링과, 이전 이미지의 형태를 망가뜨리기 위해서 $x_{t-1}$에 대한 스케일링이 각각 곱해집니다.

$$
x_t=a*x_{t-1}+b*noise
$$

그리고 디퓨전에서는 각 스케일링을 아래와 같이 적습니다. 

$$
x_t=\sqrt{1-\beta_t}*x_{t-1} + \sqrt{\beta_t}*noise
$$

여기서 노이즈를 $\epsilon \sim N(0,I)$ 표준 가우시안 분포에서 샘플링하면, timestep $t$에 상관없이 분산이 1로 유지된다는 장점이 있습니다. 

$$
* \ x_t=\sqrt{1-\beta_t}*x_{t-1} + \sqrt{\beta_t}*\epsilon
$$

그리고 여기서 $\beta_1,...,\beta_T$ 를 Variance schedule 혹은 Noise schedule 이라고 부르고, 논문에서는 $\beta_1 =0.0001$ 부터 $\beta_T=0.02$로 설정하여 시간이 지날수록 $\beta_t$ 값이 커지게 설정하였습니다. Variance schedule $\beta_t$ 또한 학습을 통해서 얻는 방식이 있지만, 사전에 Fix 해놓으면 Forward process를 네트워크에게 학습시키지 않아도 된다는 장점이 있습니다.

$$
* \ q(x_t | x_{t-1}):=N(x_{t} ; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)
$$

직관적으로 이해가 되었다면, 이제 위의 수식이 그리 어렵게 느껴지지는 않습니다. 다른 논문에서는 위 수식을 Diffusion process, Diffusion kernel 이라고 이야기 합니다 [J. Sohl-Dickstein et al., 2015]. 이미 $t$번째 상태가 결정되어 있다는 Forward process 특성과 아래 2가지 Notation을 새롭게 Define해서 이용하면 Diffusion kernel을 다시 쓸 수 있습니다. 유도 과정은 디테일적인 부분이니 생략하겠습니다.

$$
\alpha_t := 1-\beta_t, \quad \bar{\alpha}_t :=\Pi^t_{s=1} \alpha_s
$$

$$
* \ q(x_t|x_0) = N(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)
$$

즉, 원본 데이터 혹은 시작 데이터인 $x_0$만 알고 있어도 $t$번째 상태인 $x_t$를 아래와 같이 한 번에 샘플링할 수 있게 된 것입니다. 

$$
* \ x_t=\sqrt{\bar{\alpha}_t}*x_0 + \sqrt{1-\bar{\alpha}_t}*\epsilon
$$

![https://private-user-images.githubusercontent.com/144989499/288603600-6b8c06f5-b6a6-46a3-9e1d-46c6908c8024.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjAwLTZiOGMwNmY1LWI2YTYtNDZhMy05ZTFkLTQ2YzY5MDhjODAyNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02ZDRkN2RmODRhZjM4M2RhMmI3NjAwNjViZmIwNDNlZWI0OTE4MWU5NzdjY2Q2ZGI3ZmQ1M2MxNWZjY2NiYTkxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.GohSQsXGJT8Oci5DO6AUZljsyK0JOPDVEe5wrh1Xnhw](https://private-user-images.githubusercontent.com/144989499/288603600-6b8c06f5-b6a6-46a3-9e1d-46c6908c8024.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjAwLTZiOGMwNmY1LWI2YTYtNDZhMy05ZTFkLTQ2YzY5MDhjODAyNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02ZDRkN2RmODRhZjM4M2RhMmI3NjAwNjViZmIwNDNlZWI0OTE4MWU5NzdjY2Q2ZGI3ZmQ1M2MxNWZjY2NiYTkxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.GohSQsXGJT8Oci5DO6AUZljsyK0JOPDVEe5wrh1Xnhw)

이러한 형태를 얻으면 어떤 장점이 있을까요? 실제로 디퓨전 모델을 학습할 때 네트워크가 학습하는 것은 데이터에서 노이즈를 제거하는 것이라고 말했었습니다. 이 때, $t$번째 상태의 Noisy한 데이터를 얻기 위해서는 Forward process를 순차적으로 $t$번 반복하는 것이 아니라,  $T$보다 작은 임의의 Timestep $t$를 골라 위와 같은 샘플링 방식으로 $x_t$를 한 번에 얻을 수 있고 이것을 학습에 사용합니다. 즉 이로 인해, 학습 속도를 월등히 높일 수 있게 되었습니다. 

- Q. 그렇다면 왜 Diffusion kernel 이라는 용어를 사용할까요?
    
    ![https://private-user-images.githubusercontent.com/144989499/288603601-b7fb77e9-8657-4c4e-afbd-4a013015c623.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjAxLWI3ZmI3N2U5LTg2NTctNGM0ZS1hZmJkLTRhMDEzMDE1YzYyMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iZjI3NmQyZTU0MGVlODc4OWIwZDg3Yzk5ZDIxODE5OWJmYjNjMmVhYjc1OWJlNDIxZGQ1N2Q0ZTZlZDlmY2Q5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.Xsq10kVsXI_uu91LVUrhCHBF8Fa7IlgI5Xr8yz8z-PA](https://private-user-images.githubusercontent.com/144989499/288603601-b7fb77e9-8657-4c4e-afbd-4a013015c623.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjAxLWI3ZmI3N2U5LTg2NTctNGM0ZS1hZmJkLTRhMDEzMDE1YzYyMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iZjI3NmQyZTU0MGVlODc4OWIwZDg3Yzk5ZDIxODE5OWJmYjNjMmVhYjc1OWJlNDIxZGQ1N2Q0ZTZlZDlmY2Q5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.Xsq10kVsXI_uu91LVUrhCHBF8Fa7IlgI5Xr8yz8z-PA)
    

## Reverse process

![https://private-user-images.githubusercontent.com/144989499/288603603-ebfeeb9c-ff04-4b70-9574-383165fb314f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjAzLWViZmVlYjljLWZmMDQtNGI3MC05NTc0LTM4MzE2NWZiMzE0Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00M2Y4N2FkMjIxODIxZDVmYjdhNWRhZmJlMzkwZjRlOGYwMGIyZjM3NzFkYzc0NzM3MjY1ZGY5YzY4ZWQyYmI0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ARy_qWj5xbrb_LagHZUFmbluTt3LEbwqVODUx9GdIYs](https://private-user-images.githubusercontent.com/144989499/288603603-ebfeeb9c-ff04-4b70-9574-383165fb314f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjAzLWViZmVlYjljLWZmMDQtNGI3MC05NTc0LTM4MzE2NWZiMzE0Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00M2Y4N2FkMjIxODIxZDVmYjdhNWRhZmJlMzkwZjRlOGYwMGIyZjM3NzFkYzc0NzM3MjY1ZGY5YzY4ZWQyYmI0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ARy_qWj5xbrb_LagHZUFmbluTt3LEbwqVODUx9GdIYs)

Forward process를 잘 정의했으니, 이를 역과정으로 취하게 되면 $q(x_{t-1}|x_t)$를 이용해서 가우시안 노이즈 $x_T$로부터 깨끗한 이미지 $x_0$를 얻을 수 있습니다. 하지만 아쉽게도 $q(x_{t-1}|x_t)$를 정확히 아는 것은 쉽지 않습니다. 그러므로 모델 $p_\theta$의 학습을 통해서 조건부 분포 $q(x_{t-1}|x_t)$를 근사하도록 하여 Reverse process를 진행하고자 합니다.

$$
q(x_{t-1}|x_t) \approx p_\theta(x_{t-1} | x_t)
$$

여기서 추가적으로 조건이 하나 붙습니다. Forward process에서 다음 Timestep으로 넘어갈 때, 얼마만큼의 노이즈를 더해줄지 결정하는 **Noise schedule $\beta_t$가 충분히 작다면**, 저희가 알아내고 싶은 $**q(x_{t-1}|x_t)$가 정규분포(가우시안분포)를 따른다고 가정**할 수 있습니다. 갑자기 무슨 맥락인지 이해가 어려울 수 있습니다. $\beta_t$가 충분히 작다는 것은 $x_t$와 $x_{t-1}$ 사이의 변화가 굉장히 작다는 것이고, 이러한 변화는 정규분포를 따르는 것으로 간주할 수 있기 때문입니다. 

만약 여러분이 특정한 분포를 구해야하는데 그 분포가 정규분포를 따른다면, 분석이 용이하는 등 굉장히 많은 이점들이 있을 것입니다. 저자들도 이러한 Motivation을 통해 Reverse process를 진행하기 위해서 구해야하는 조건부 분포 $q(x_{t-1}|x_t)$가 정규분포를 따른다고 가정했다고 생각하시면 됩니다. 

이제 학습해야할 모델 $p_\theta$가 정규분포로 모델링할 수 있고, Reverse process도 마찬가지로 마르코프 체인에 의해 아래와 같이 표현할 수 있습니다.

$$
p_\theta(x_0) := \int p_\theta(x_{0:T}) dx_{1:T}
$$

$$
* \ p_\theta(x_{0:T}):=p(x_T)\Pi^T_{t=1}p_\theta (x_{t-1} | x_t)
$$

$$
* \  p_\theta(x_{t-1} | x_t):=N(x_{t-1} ; \mu_\theta(x_t,t), \Sigma_\theta(x_t,t))
$$

## Training objective of diffusion

이번 장에서는 디퓨전 모델의 Objective function에 대해 알아보겠습니다.

### Objective function 유도

디퓨전 모델의 학습은 아래와 같이 Negative log likelihood의 Variational upper(lower) bound를 최적화 하는 방식으로 이루어집니다. (유도과정에서 $**$표시가 되어있는 식은 논문에 적혀있는 식입니다)

$$
\mathbb{E} \left[-\log p_\theta(x_0)\right] \ ** 
$$

Bayes 정리의 의해서, 아래처럼 표현할 수 있습니다.

$$
= \mathbb{E}_q \left[-\log \frac{p_\theta(x_0,x_1,x_2,...,x_T)}{p_\theta(x_1,x_2,...,x_T | x_0)} \right] = \mathbb{E}_q \left[-\log \frac{p_\theta(x_{0:T})}{p_\theta(x_{1:T} | x_0)} \right]
$$

그리고 위에서 미리 정의해두었던 Poseterior $\ q(x_{1:T} | x_0):= \Pi^T_{t=1}q(x_{t} | x_{t-1})$ 를 분자, 분모에 곱해줍니다.

$$
= \mathbb{E}_q \left[-\log \frac{p_\theta(x_{0:T})}{p_\theta(x_{1:T} | x_0)}  \cdot \frac{q(x_{1:T} | x_0)}{q(x_{1:T} | x_0)} \right]
$$

그러면 왼쪽 분모 $p_\theta(x_{1:T} | x_0)$와 오른쪽 분자 $q(x_{1:T} | x_0)$ 는 KL-Divergence로 인해 임의의 양수 값을 가진 상태로 밖으로 빠져나오게 됩니다.

$$
\leq \mathbb{E}_q \left[-\log \frac{p_\theta(x_{0:T})}{q(x_{1:T} | x_0)} \right] \ **
$$

분자, 분모에 있는 항들은 둘 다 이미 사전에 마르코프 체인을 통해 정의된 항이므로 아래와 같이 표현할 수 있습니다.

$$
= \mathbb{E}_q \left[-\log \frac{p(x_T)\Pi^T_{t=1}p_\theta (x_{t-1} | x_t)}{\Pi^T_{t=1}q(x_{t} | x_{t-1})} \right] = \mathbb{E}_q \left[-\log p_\theta(x_T)-\log \frac{\Pi^T_{t=1}p_\theta (x_{t-1} | x_t)}{\Pi^T_{t=1}q(x_{t} | x_{t-1})} \right]
$$

$$
= \mathbb{E}_q \left[-\log p_\theta(x_T)-\sum_{t \geq 1} \log \frac{p_\theta (x_{t-1} | x_t)}{q(x_{t} | x_{t-1})} \right] := L **
$$

이렇게 정의된 Loss function을 논문의 Appendix에 따라 아래와 같이 다시 표현할 수 있습니다.(일부 과정은 생략하였으니 직접 참고하시기 바랍니다)

$$
L = \mathbb{E}_q \left[-\log p_\theta(x_T)-\sum_{t > 1} \log \frac{p_\theta (x_{t-1} | x_t)}{q(x_{t} | x_{t-1})} -\log\frac{p_\theta (x_{0} | x_1)}{q(x_{1} | x_{0})} \right]
$$

$$
= \mathbb{E}_q \left[-\log \frac{p_\theta(x_T)}{q(x_t|x_0)} -\sum_{t > 1} \log \frac{p_\theta (x_{t-1} | x_t)}{q(x_{t-1} | x_{t},x_0)} -\log p_\theta (x_{0} | x_1) \right]
$$

최종 Ojective function은 아래와 같이 표현할 수 있습니다. 

$$
= \mathbb{E}_q \left[ D_{KL}(q(x_T|x_0) || p(x_T))  +  \sum_{t>1} D_{KL}(q(x_{t-1}|x_t,x_0) || p_\theta(x_{t-1}|x_t))-\log p_\theta(x_0|x_1) \right]
$$

### Objective에서 바라본 VAE 와의 연관성

우리가 일반적으로 알고 있는 VAE와 디퓨전 모델을 비교해보면서 Objective function의 이해를 도와보겠습니다. (그림은 [https://www.youtube.com/watch?v=_JQSMhqXw-4](https://www.youtube.com/watch?v=_JQSMhqXw-4) 참조)

![https://private-user-images.githubusercontent.com/144989499/288603605-aeb521cd-91cb-4169-b92c-074fee962b2f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjA1LWFlYjUyMWNkLTkxY2ItNDE2OS1iOTJjLTA3NGZlZTk2MmIyZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmQ4MzQ3M2RiZTI1NGE4MDExZTgyZmI3ZmZkOTc2ZDU0YTg3NGRiMDQ2Yjg0NGZkNDkzNjM4YmU4YmE5ZGVjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.6JU5-3XzpTkQdKkU-Wz5pYsumIsNhRGZr-nnVlNqvRs](https://private-user-images.githubusercontent.com/144989499/288603605-aeb521cd-91cb-4169-b92c-074fee962b2f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjA1LWFlYjUyMWNkLTkxY2ItNDE2OS1iOTJjLTA3NGZlZTk2MmIyZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmQ4MzQ3M2RiZTI1NGE4MDExZTgyZmI3ZmZkOTc2ZDU0YTg3NGRiMDQ2Yjg0NGZkNDkzNjM4YmU4YmE5ZGVjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.6JU5-3XzpTkQdKkU-Wz5pYsumIsNhRGZr-nnVlNqvRs)

![https://private-user-images.githubusercontent.com/144989499/288603607-e71ad537-926e-4d9c-8c42-2ea1f3f3008d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjA3LWU3MWFkNTM3LTkyNmUtNGQ5Yy04YzQyLTJlYTFmM2YzMDA4ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kNzI1ZTkzZjUwNGI2NWU5OTdkNzY2MGJmYmVhY2YxYjRiOTJiZjM5MjQ2NzJkY2JkOTMyODdhNjkzNTJiMWViJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.8N_iRqsFM2PtJ7rlFiPdemBJExYuICcEQ8z-MD3-7gI](https://private-user-images.githubusercontent.com/144989499/288603607-e71ad537-926e-4d9c-8c42-2ea1f3f3008d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjA3LWU3MWFkNTM3LTkyNmUtNGQ5Yy04YzQyLTJlYTFmM2YzMDA4ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kNzI1ZTkzZjUwNGI2NWU5OTdkNzY2MGJmYmVhY2YxYjRiOTJiZjM5MjQ2NzJkY2JkOTMyODdhNjkzNTJiMWViJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.8N_iRqsFM2PtJ7rlFiPdemBJExYuICcEQ8z-MD3-7gI)

위 그림을 보시면, VAE는 1개의 Latent variable $z_1$을 가지고 있습니다. 하지만 디퓨전 모델은 사용자가 직접 디퓨전 스텝 수인 $T$를 결정하여 총 $T$개의 Latent variables $z_1,z_2,...,z_T$를 가지고 있습니다.

![https://private-user-images.githubusercontent.com/144989499/288603610-027acef2-8121-4c08-a1ea-45c630010932.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjEwLTAyN2FjZWYyLTgxMjEtNGMwOC1hMWVhLTQ1YzYzMDAxMDkzMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iM2MxY2JiM2U1MTQyOTFjYTRhMmQ0YzdlMjM1YjdiODVmMDYwY2FmODJhMGE5NmVlYmFiYWI5MDk3MWQ5ZTgyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ZgIEvARk-hrPGzLXz8Y91G7CfHlhzgMNbdHhR80XpxU](https://private-user-images.githubusercontent.com/144989499/288603610-027acef2-8121-4c08-a1ea-45c630010932.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjEwLTAyN2FjZWYyLTgxMjEtNGMwOC1hMWVhLTQ1YzYzMDAxMDkzMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iM2MxY2JiM2U1MTQyOTFjYTRhMmQ0YzdlMjM1YjdiODVmMDYwY2FmODJhMGE5NmVlYmFiYWI5MDk3MWQ5ZTgyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.ZgIEvARk-hrPGzLXz8Y91G7CfHlhzgMNbdHhR80XpxU)

Loss 형태를 비교해보면 전체적인 형태는 비슷하면서, 디퓨전에는 Latent variables가 $T-1$개 더 많이 갖고 있으므로 Denoising process를 담당하는 $T-1$개의 항이 추가되었다고 이해하시면 될 것 같습니다.

![https://private-user-images.githubusercontent.com/144989499/288603613-f2003582-118f-40be-bdf1-3288b1d5b7ae.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjEzLWYyMDAzNTgyLTExOGYtNDBiZS1iZGYxLTMyODhiMWQ1YjdhZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYmY4YzQ5Mzg3NjBlYzQwNWY3MGJjYjhhMmFkMzZmMDE0MzgwMGJiMDRiZGIyMTBlMzllNTBlYmViMjg0YjM5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.j0F9Mk26G2D6ojl0CubmJVdz5EfQQHwbgVdzm26ZqyA](https://private-user-images.githubusercontent.com/144989499/288603613-f2003582-118f-40be-bdf1-3288b1d5b7ae.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjEzLWYyMDAzNTgyLTExOGYtNDBiZS1iZGYxLTMyODhiMWQ1YjdhZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYmY4YzQ5Mzg3NjBlYzQwNWY3MGJjYjhhMmFkMzZmMDE0MzgwMGJiMDRiZGIyMTBlMzllNTBlYmViMjg0YjM5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.j0F9Mk26G2D6ojl0CubmJVdz5EfQQHwbgVdzm26ZqyA)

### $L_T$ and $L_0$

- $L_T$는 VAE에서 Posterior가 Prior(가우시안 분포)를 따르도록 강제하는 Loss term입니다.  특히 파라미터 $\theta$와 Independent 하기 때문에 학습과정에서 무시해도 되는 항입니다.
- $L_0$는 결과에 큰 영향을 미치지 않을정도로 작기 때문에 일반적으로 크게 신경쓰지 않는 항입니다.

### $L_{1:T-1}$

사실 $L_{1:T-1}$ Loss term이 가장 중요합니다. $L_{1:T-1}$을 이해하기 위해서, $p_\theta(x_{t-1}|x_t)$와 KL-Divergence를 계산하는 $q(x_{t-1}|x_t,x_0)$ 항에 대해 추가적으로 몇 가지 언급을 하고 넘어가겠습니다. 

위에서 말씀 드렸듯이, 결국에 지금 하고자 하는 것은 Reverse process에 필요한 조건부 분포 $q(x_{t-1}|x_t)$를 정확히 알지 못하기 때문에 $p_\theta(x_{t-1}|x_t)$가 $q(x_{t-1}|x_t)$를 근사하도록 네트워크를 학습해서 Reverse process를 진행하는 것입니다. 그 과정에서 디퓨전 모델의 Objective function을 변형해보니, $q(x_{t-1}|x_t,x_0)$라는 항이 나오게 됐습니다. 

논문에서 말하기를  $q(x_{t-1}|x_t)$는 정확하게 알 수 없지만, $x_0$를 컨디션으로 준 $q(x_{t-1}|x_t,x_0)$는 Tractable 하다고 합니다. 그래서 유도과정을 통해 아래와 같은 정규분포의 형태로 표현이 가능하다고 합니다.
(유도 과정은 [https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#ldm](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#ldm) 참조)

$$
* \ q(x_{t-1} | x_{t}, x_0):=N(x_{t-1} ; \tilde{\mu}_t(x_t,x_0), \tilde{\beta}_t I)
$$

$$
\tilde{\mu}_t(x_t,x_0) := \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0 +\frac{\sqrt{\alpha}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t, \quad \tilde{\beta}_t := \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t
$$

이제 KL-Divergence를 계산하는 분포까지 알아냈으니, 결정해야할 것은 $p_\theta(x_{t-1} | x_t):=N(x_{t-1} ; \mu_\theta(x_t,t), \Sigma_\theta(x_t,t))$ 입니다. 즉, $p_\theta(x_{t-1}|x_t)$ 의 평균인 $\mu_\theta(x_t,t)$와 분산인 $\Sigma_\theta(x_t,t)$을 결정해야 합니다. 

논문에서 말하기를 $\Sigma_\theta(x_t,t)$를 학습을 통해 얻을 수도 있었지만, Time-dependet한 상수 $\Sigma_\theta(x_t,t) =\sigma^2_tI$로 설정했다고 합니다. 이 때 $\sigma^2_t =\beta_t$ 와 $\sigma^2_t = \tilde{\beta}_t = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$ 둘 다 가능하여 실험을 진행했는데, 큰 차이가 없었다고 합니다. 즉 $p_\theta(x_{t-1}|x_t)$의 분산은 학습을 통해서 구하는 것이 아니라 이미 결정된 상수입니다.

$$
p_\theta(x_{t-1} | x_t) =N(x_{t-1} ; \mu_\theta(x_t,t), \sigma^2_tI)
$$

이제 모델 학습을 위해 결정할 것은 $p_\theta(x_{t-1}|x_t)$의 평균 $\mu_\theta(x_t,t)$만 남아 있습니다. $L_{t-1}$을 아래와 같이 다시 표현하였습니다. 

$$
L_{t-1}=\mathbb{E}_q\left[\frac{1}{2\sigma^2_t} ||\tilde{\mu}_t(x_t,x_0)-\mu_\theta(x_t,t)||^2 \right] +C
$$

그리고 Forward process를 설명하면서 $x_0$에서 한 번에 $x_t$를 샘플링할 수 있는 두 변수 사이의 관계식을 알아냈습니다.$( x_t=\sqrt{\bar{\alpha}_t}*x_0 + \sqrt{1-\bar{\alpha}_t}*\epsilon)$ 이 관계식을 이용해서 $x_0$를 $x_t$에 대해 표현하면 아래와 같습니다.  

$$
L_{t-1} - C
$$

$$
=\mathbb{E}_{x_0,\epsilon}\left[\frac{1}{2\sigma^2_t} ||\tilde{\mu}_t \left(x_t(x_0,\epsilon),\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t(x_0,\epsilon)-\sqrt{1-\bar{\alpha}}\epsilon) \right)-\mu_\theta(x_t(x_0,\epsilon),t)||^2 \right]
$$

그리고 $\tilde{\mu}_t(x_t,x_0)$  도 사전에 정의했으므로, 식을 다시 표현하면 아래와 같습니다.

$$
=\mathbb{E}_{x_0,\epsilon}\left[\frac{1}{2\sigma^2_t} \left|\left|\frac{1}{\sqrt{\alpha_t}} \left(x_t(x_0,\epsilon)-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon \right)-\mu_\theta(x_t(x_0,\epsilon),t) \right|\right|^2 \right]
$$

위의 식을 보면 $**\mu_\theta$는 학습과정동안 인풋으로 주어진 $x_t$에 대해서 $\frac{1}{\sqrt{\alpha_t}} \left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon \right)$를 예측**하면 Loss를 감소시킬수 있게 됩니다. 이를 다시 Parameterization 해보면,

$$
\mu_\theta(x_t,t) = \tilde{\mu}_t \left(x_t,\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t-\sqrt{1-\bar{\alpha}}\epsilon_\theta(x_t)) \right)
$$

$$
=\frac{1}{\sqrt{\alpha_t}} \left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t,t) \right)
$$

입니다. 즉, **인풋으로 받은 $x_t$로부터 $\epsilon$을 예측하는 $\epsilon_\theta$를 학습하는 것**과 같다고 볼 수 있습니다. 최종적으로 Objective function을 다시 적어보면 아래와 같습니다.

$$
* \ \mathbb{E}_{x_{0},\epsilon} \left[\frac{\beta^2_t}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)} \left|\left| \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 +\sqrt{1-\bar{\alpha}_t}\epsilon,t)\right|\right|^2 \right]
$$

$$
= \ \mathbb{E}_{x_{0},\epsilon} \left[\frac{\beta^2_t}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)} \left|\left| \epsilon - \epsilon_\theta(x_t,t)\right|\right|^2 \right]
$$

요약해보면 Reverse process를 위해서 $p_\theta(x_{t-1}|x_t)$의 분산$\Sigma_\theta(x_t,t) =\sigma^2_tI$로 고정하고, 평균인 $\mu_\theta(x_t,t)$은 어떠한 형태로 학습할지 고를 수 있습니다. 하나는 $\tilde{\mu}_t$를 예측하는 방법과, 또 다른 방법은 $\epsilon$을 예측하는 방법입니다. 

$\epsilon$-prediction을 사용했을 때 몇가지 특징이 있습니다. 

- 첫 번째는 샘플링 방식이 Langevin dynamics 형태와 닮았다는 점입니다. $x_{t-1} \sim p_\theta(x_{t-1}|x_t)$ 에서 샘플링을 하는 것은 $x_{t-1}=\frac{1}{\sqrt{\alpha_t}} \left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t,t) \right)+\sigma_tz$ 를 계산하는 것과 같습니다. 실제로 DDPM의 Algorithm2에서 볼 수 있듯이 샘플링의 형태가 Langevin dynamics와 유사한 형태를 가졌습니다.
    
    ![https://private-user-images.githubusercontent.com/144989499/288603616-7d3eef5d-7f8e-454e-be23-cbb5bcdb4d7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE2LTdkM2VlZjVkLTdmOGUtNDU0ZS1iZTIzLWNiYjViY2RiNGQ3Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMDRmNDFkYjc4NWI4ZmM0OWFjNDU0MTE3MzQyZDRiNjE2NTA4YzgyYTJlYjkwYzlhM2FlNmZhNWRlMTQwNGFlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.kUm5xsYtGL9XtwdEnbr8P6yFVWXM1lvI29eOdl8MeqY](https://private-user-images.githubusercontent.com/144989499/288603616-7d3eef5d-7f8e-454e-be23-cbb5bcdb4d7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE2LTdkM2VlZjVkLTdmOGUtNDU0ZS1iZTIzLWNiYjViY2RiNGQ3Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMDRmNDFkYjc4NWI4ZmM0OWFjNDU0MTE3MzQyZDRiNjE2NTA4YzgyYTJlYjkwYzlhM2FlNmZhNWRlMTQwNGFlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.kUm5xsYtGL9XtwdEnbr8P6yFVWXM1lvI29eOdl8MeqY)
    
    $$
    \text{Langevin dynamics: }x_i = x_{i-1} + \frac{\epsilon}{2} \nabla_x \log p(x) + \sqrt{\epsilon}z_i
    $$
    

- 두 번째는 $\epsilon$-prediction의 Objective function은 [Y. Song, Generative Modeling by Estimating Gradients of the Data Distribution, NeurIPS 2019]의 Denoising score mathcing 방식의 Objective와도 닮은 형태를 가졌습니다. 복잡한 형태를 갖는 디퓨전 모델의 Varitational bound를 비교적 단순한 형태로 변형할 수 있습니다.
    
    $$
    l(\theta;\sigma) \triangleq \frac{1}{2}\mathbb{E}_{p_{data}(x)} \mathbb{E}_{\tilde{x} \sim N(x,\sigma^2I)} \left[ \left| \left| s_\theta(\tilde{x},\sigma) + \frac{\tilde{x}-x}{\sigma^2}\right| \right|^2_2 \right]
    $$
    

- 세 번째는 논문에서 실험결과를 통해서 $\tilde{\mu}_t$-prediction 보다 $\epsilon$-prediction의 성능이 더 좋게 나왔음을 보였습니다.

### Simplified training objective

저자들은 성능의 우수성과 구현의 간편함을 위해 최종 Training objective를 더욱 간단화 했습니다. Loss term에 곱해져있던 Time-dependent 한 weight $\lambda_t = \frac{\beta^2_t}{2\sigma^2_t\alpha_t(1-\bar{\alpha}_t)}=1$ 로 설정하여 아래와 같이 최종 Training objective를 정의했습니다. 

$$
* \ L_{\text{simple}} (\theta):= \mathbb{E}_{t,x_0,\epsilon} \left[ ||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon,t)||^2\right]
$$

![https://private-user-images.githubusercontent.com/144989499/288603618-d0ecb896-be5a-4b15-8a48-bca5cc868b39.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE4LWQwZWNiODk2LWJlNWEtNGIxNS04YTQ4LWJjYTVjYzg2OGIzOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02YjNmZWE4ODUxNGVhNTAyODI0NzUzMzNiNGJmM2ZlNDAxODA2MDJlNmU5ZmNjOGE0ODY2MTUwZmQ0M2I4ZmEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.KUXiR9tuZraEm2mh8VABjEZ0dqDglF5VTEhZxSTRvog](https://private-user-images.githubusercontent.com/144989499/288603618-d0ecb896-be5a-4b15-8a48-bca5cc868b39.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE4LWQwZWNiODk2LWJlNWEtNGIxNS04YTQ4LWJjYTVjYzg2OGIzOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02YjNmZWE4ODUxNGVhNTAyODI0NzUzMzNiNGJmM2ZlNDAxODA2MDJlNmU5ZmNjOGE0ODY2MTUwZmQ0M2I4ZmEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.KUXiR9tuZraEm2mh8VABjEZ0dqDglF5VTEhZxSTRvog)

## Summary

- **Forward process**
    - $q(x_t|x_0) = N(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)$
    - $x_t=\sqrt{\bar{\alpha}_t}*x_0 + \sqrt{1-\bar{\alpha}_t}*\epsilon, \ \epsilon \sim N(0,I)$
        - $\beta_1 = 0.0001, \  \beta_T = 0.02$
        - $\alpha_t := 1-\beta_t, \ \bar{\alpha}_t :=\Pi^t_{s=1} \alpha_s$
- **Reverse process**
    - $p_\theta(x_{t-1} | x_t) =N(x_{t-1} ; \mu_\theta(x_t,t), \sigma^2_tI)$
    - $x_{t-1}=\frac{1}{\sqrt{\alpha_t}} \left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t,t) \right)+\sigma_t \epsilon , \ \epsilon \sim N(0,I)$
        - $\sigma_t = \tilde{\beta}_t = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$ or $\sigma_t = \beta_t$
- **Loss**
    - $\epsilon - \epsilon_\theta(x_t)= \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon,t)$
        - $\epsilon_\theta$: Prediction network
- **Training**
    
    ![https://private-user-images.githubusercontent.com/144989499/288603618-d0ecb896-be5a-4b15-8a48-bca5cc868b39.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE4LWQwZWNiODk2LWJlNWEtNGIxNS04YTQ4LWJjYTVjYzg2OGIzOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02YjNmZWE4ODUxNGVhNTAyODI0NzUzMzNiNGJmM2ZlNDAxODA2MDJlNmU5ZmNjOGE0ODY2MTUwZmQ0M2I4ZmEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.KUXiR9tuZraEm2mh8VABjEZ0dqDglF5VTEhZxSTRvog](https://private-user-images.githubusercontent.com/144989499/288603618-d0ecb896-be5a-4b15-8a48-bca5cc868b39.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE4LWQwZWNiODk2LWJlNWEtNGIxNS04YTQ4LWJjYTVjYzg2OGIzOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02YjNmZWE4ODUxNGVhNTAyODI0NzUzMzNiNGJmM2ZlNDAxODA2MDJlNmU5ZmNjOGE0ODY2MTUwZmQ0M2I4ZmEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.KUXiR9tuZraEm2mh8VABjEZ0dqDglF5VTEhZxSTRvog)
    
    - Timestep $t$를 결정한 후 원본 데이터 $x_0$에 Timestep에 대응하는 노이즈를 더해줍니다.
    - 네트워크의 인풋으로 Noisy한 데이터 $x_t$와 Timestep $t$를 같이 넣어줍니다.
    - 네트워크는 아웃풋으로 얼마만큼의 노이즈가 더해졌는지 예측합니다.
- **Sampling**
    
    ![https://private-user-images.githubusercontent.com/144989499/288603616-7d3eef5d-7f8e-454e-be23-cbb5bcdb4d7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE2LTdkM2VlZjVkLTdmOGUtNDU0ZS1iZTIzLWNiYjViY2RiNGQ3Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMDRmNDFkYjc4NWI4ZmM0OWFjNDU0MTE3MzQyZDRiNjE2NTA4YzgyYTJlYjkwYzlhM2FlNmZhNWRlMTQwNGFlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.kUm5xsYtGL9XtwdEnbr8P6yFVWXM1lvI29eOdl8MeqY](https://private-user-images.githubusercontent.com/144989499/288603616-7d3eef5d-7f8e-454e-be23-cbb5bcdb4d7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjE2LTdkM2VlZjVkLTdmOGUtNDU0ZS1iZTIzLWNiYjViY2RiNGQ3Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMDRmNDFkYjc4NWI4ZmM0OWFjNDU0MTE3MzQyZDRiNjE2NTA4YzgyYTJlYjkwYzlhM2FlNmZhNWRlMTQwNGFlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.kUm5xsYtGL9XtwdEnbr8P6yFVWXM1lvI29eOdl8MeqY)
    
    - 임의의 가우시안 노이즈 $x_T$에서 시작하여 순차적으로 노이즈를 제거하여 $x_0$ 까지 복원합니다.

# Experiments

실험세팅은 아래와 같습니다.

![https://private-user-images.githubusercontent.com/144989499/288603620-bb2b1242-7abd-4626-bc3b-6fda0ed8530a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjIwLWJiMmIxMjQyLTdhYmQtNDYyNi1iYzNiLTZmZGEwZWQ4NTMwYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03NzE3NmU0ZjYzZTk0YjAyMmI4YjAwMzFlYjgwNjJlNThhNTdlN2Q0YzJmNjAyZDRiODEwNDFhMGI2OGIzNzVlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.10rgpcdg1-RkRFf9uMemx3p3DqHRRPSTWPkCFBmwXM8](https://private-user-images.githubusercontent.com/144989499/288603620-bb2b1242-7abd-4626-bc3b-6fda0ed8530a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjIwLWJiMmIxMjQyLTdhYmQtNDYyNi1iYzNiLTZmZGEwZWQ4NTMwYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03NzE3NmU0ZjYzZTk0YjAyMmI4YjAwMzFlYjgwNjJlNThhNTdlN2Q0YzJmNjAyZDRiODEwNDFhMGI2OGIzNzVlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.10rgpcdg1-RkRFf9uMemx3p3DqHRRPSTWPkCFBmwXM8)

- Diffusion step $T=1000$
- Backbone model: U-Net
- Time embedding: Sinusoidal positional embedding
- Group normalization 사용

## Sample quality results

![https://private-user-images.githubusercontent.com/144989499/288603621-9bd7e794-4b23-42cd-b1b7-7afded7d829c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjIxLTliZDdlNzk0LTRiMjMtNDJjZC1iMWI3LTdhZmRlZDdkODI5Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xYjVhODA4NzRiOWE1MmYyMTg5MTY2YmU2ZTUxNTFhM2Y3NTQ2YmM0ODg4N2ZkZTI0Njk2NGY5OGI5MzhjMWE1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.V0ZukzpsoBGgXKYWtaofggdBAjbRhnqHm44UWHVkb24](https://private-user-images.githubusercontent.com/144989499/288603621-9bd7e794-4b23-42cd-b1b7-7afded7d829c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjIxLTliZDdlNzk0LTRiMjMtNDJjZC1iMWI3LTdhZmRlZDdkODI5Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xYjVhODA4NzRiOWE1MmYyMTg5MTY2YmU2ZTUxNTFhM2Y3NTQ2YmM0ODg4N2ZkZTI0Njk2NGY5OGI5MzhjMWE1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.V0ZukzpsoBGgXKYWtaofggdBAjbRhnqHm44UWHVkb24)

## Reverse process parameterization and training objective ablation

![https://private-user-images.githubusercontent.com/144989499/288603624-8cbc0ca7-b871-42aa-85ef-8159da02a5de.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjI0LThjYmMwY2E3LWI4NzEtNDJhYS04NWVmLTgxNTlkYTAyYTVkZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iZGJjODZiZjExMjhmMTQ5NjFlMWEyYTM2ZjM1MWRiMWVkNzlhMDZiMmI1YTg5NjRlNTk0MGU5NTVjN2Q0NzY5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.iujMvJ9zVgtuvz9ILE_bdEVJdovn7ACAxtw_SbrJ22M](https://private-user-images.githubusercontent.com/144989499/288603624-8cbc0ca7-b871-42aa-85ef-8159da02a5de.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDE5MTU0MjgsIm5iZiI6MTcwMTkxNTEyOCwicGF0aCI6Ii8xNDQ5ODk0OTkvMjg4NjAzNjI0LThjYmMwY2E3LWI4NzEtNDJhYS04NWVmLTgxNTlkYTAyYTVkZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBSVdOSllBWDRDU1ZFSDUzQSUyRjIwMjMxMjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIzMTIwN1QwMjEyMDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iZGJjODZiZjExMjhmMTQ5NjFlMWEyYTM2ZjM1MWRiMWVkNzlhMDZiMmI1YTg5NjRlNTk0MGU5NTVjN2Q0NzY5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.iujMvJ9zVgtuvz9ILE_bdEVJdovn7ACAxtw_SbrJ22M)

# Reference

- [https://arxiv.org/pdf/2006.11239.pdf](https://arxiv.org/pdf/2006.11239.pdf)
- [https://arxiv.org/pdf/1503.03585.pdf](https://arxiv.org/pdf/1503.03585.pdf)
- [https://arxiv.org/pdf/1907.05600.pdf](https://arxiv.org/pdf/1907.05600.pdf)
- [https://cvpr2022-tutorial-diffusion-models.github.io/](https://cvpr2022-tutorial-diffusion-models.github.io/)
- [https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#ldm](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#ldm)
- [https://happy-jihye.github.io/diffusion/diffusion-1/](https://happy-jihye.github.io/diffusion/diffusion-1/)
- [https://www.youtube.com/watch?v=_JQSMhqXw-4](https://www.youtube.com/watch?v=_JQSMhqXw-4)
- [https://www.youtube.com/watch?v=jaPPALsUZo8](https://www.youtube.com/watch?v=jaPPALsUZo8)